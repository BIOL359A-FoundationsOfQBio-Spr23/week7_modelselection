{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Complexity, Overfitting, and Model Selection\n",
    "### Spring 2023, Week 7\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Develop and run increasingly complex MLR models\n",
    "-  Evaluate performance of MLR models based on Cross-Validation\n",
    "-  Evaluate other supervised learning models based on Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us discuss the dataset and the problem: \n",
    "\n",
    "Imagine you are a want to leverage small interfering RNAs (siRNA) to adjust the transcription rate of a gene. \n",
    "The thermodynamics (a characterization of equilibrium energy) of these structures is closely tied to how accessible the DNA is for transcription (as well as any other biomolecule _complex_ that you may encounter). \n",
    "The main property we care about here is the Gibbs Free Energy, $\\Delta G$. \n",
    "\n",
    "$\\Delta G$ describes the strength of localization between two molecules. The more negative the $\\Delta G$, the more energy it will take to separate these molecules (alternatively, the more likely these molecules will form a complex). When considering multiple complexes that can form, its often useful to use this to evaluate the __competition__ between which complexes will form. These concepts are closely tied with proability and statistics. \n",
    "\n",
    "Here is the competition system we are studying:\n",
    "\n",
    "\n",
    "![](system.png)\n",
    "\n",
    "Therefore, a lower activity means that we have a more effective inhibition.\n",
    "\n",
    "Source: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr23/week7_modelselection\n",
    "!mkdir ./data\n",
    "!cp week7_modelselection/data/* ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (5,5)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize':FIG_SIZE}) \n",
    "sns.set_style(\"whitegrid\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name | Description | \n",
    "| --- | --- |\n",
    "| Target seq | target mRNA GenBank sequence accession number |\n",
    "| Start | start position on target mRNA | \n",
    "| End | end position on target mRNA | \n",
    "| Sequence | siRNA sequence |\n",
    "| G | nucleotide content, G |\n",
    "| U | nucleotide content, U | \n",
    "| bi | stability (∆G) of dimers of siRNAs antisense strands |  \n",
    "| uni | siRNA antisense strand intra-molecular structure stability (∆G) |\n",
    "| duplex | ∆G of sense-antisense siRNA duplexes | \n",
    "| Pos1 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 1 | \n",
    "| Pos2 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 2 | \n",
    "| Pos6 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 6 | \n",
    "| Pos13 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 13 | \n",
    "| Pos14 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 14 | \n",
    "| Pos18 | stability profile (∆G) of each two neighboring base pairs in the siRNA sense-antisense, position 18 | \n",
    "| Dif_5-3 | ∆G difference between position 1 and 18 |\n",
    "| Content+ | preferred dinucleotide content |\n",
    "| Content- | avoided dinucleotide content | \n",
    "| Cons+ | position-dependent nucleotide consensus, preferred |\n",
    "| Cons- | position-dependent nucleotide consensus, avoided |\n",
    "| Cons_Sum | position-dependent nucleotide consensus, sum |\n",
    "| Hyb19 | number of potential target copies in mRNAs (∆G threshold) |\n",
    "| target | local target mRNA stabilities (∆G) |\n",
    "| Activity | gene expression |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/data.csv\")\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2-5: Dataset\n",
    "We are going to take out the non-numeric features. There are a couple thigns that we could potentially do with them, but that type of feature engineering is outside the scope of this class. __Refer to the table below to answer questions 2 and 3.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical(df):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    num_df = df.select_dtypes(include=numerics)\n",
    "    return num_df\n",
    "    \n",
    "num_dataset = get_numerical(dataset)\n",
    "num_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataset.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Training Data and Test Data\n",
    "\n",
    "When viewing datasets, you can treat every feature as a __dimension__ (think about how each feature can be represented on an axis). Below are PCA (Principal Component Analysis) plots, which are a way to visualize high-dimensional datasets in fewer dimensions. We will cover this analysis later in the course, but if points are close on a PCA plot, it generally means they contain similar information.\n",
    "\n",
    "As a researcher, you may need to take a look at your training/test split to see if you are including any bias in your training/test data. From class, Prof. Bagheri gave the example of your training data containing all of the placebo patients and none of them ending up in the training set, which leads to unbalanced data. \n",
    "\n",
    "Below are 4 different PCA plots, with training-test splits. Which are good? Which are not good? What type of bias would you introduce? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def performPCA(X, n_dimensions=2, drop_columns=[\"Start\", \"End\"]):\n",
    "    \"\"\"\n",
    "    Uses sklearn PCA tool to perform PCA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    n_dimensions: Number of PCs to fit\n",
    "    \n",
    "    output:\n",
    "    X_pca: Pandas dataframe with column titles of PC1,...,PCn\n",
    "    \"\"\"\n",
    "    X_data = get_numerical(X)\n",
    "    if drop_columns: X_data.drop([], axis=1)\n",
    "    X_standardized = StandardScaler().fit_transform(X_data)\n",
    "    pca = PCA(n_components=n_dimensions)\n",
    "    pca.fit(X_standardized)\n",
    "    X_pca_array = pca.transform(X_standardized)\n",
    "    column_names = ['PC{}'.format(i+1) for i in range(n_dimensions)] \n",
    "    X_pca = pd.DataFrame(X_pca_array, columns=column_names)\n",
    "    return X_pca\n",
    "\n",
    "def makeplots(pca_data):\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data, color=\"grey\",alpha=.3, label=\"Training\")\n",
    "    biased_A = pca_data[pca_data[\"PC1\"]>-1]\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=biased_A.sample(130), color=\"blue\", label=\"Test\")\n",
    "    plt.title(\"A: ($n_{test}=130$)\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data, color=\"grey\",alpha=.3, label=\"Training\")\n",
    "    biased_B = pca_data[pca_data[\"PC2\"]<1.5]\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=biased_B.sample(130), color=\"orange\", label=\"Test\")\n",
    "    plt.title(\"B: ($n_{test}=130$)\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data, color=\"grey\",alpha=.3, label=\"Training\")\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data.sample(130), color=\"purple\", label=\"Test\")\n",
    "    plt.title(\"C: ($n_{test}=130$)\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data, color=\"grey\",alpha=.3, label=\"Training\")\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_data.sample(40), color=\"red\", label=\"Test\")\n",
    "    plt.title(r\"D: ($n_{test}=40$)\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "\n",
    "pca = performPCA(dataset)\n",
    "makeplots(pca)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7: MLR review\n",
    "\n",
    "We will perform an MLR on __all__ of the quantitative variables in the dataset. Try to interpret the variables. Does anything seem odd? Compare the coefficients to the original ranges and typical values of the features they are associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def linear_regression(df, feature_cols, response_col, standardized = True, print_coef=True):\n",
    "    \"\"\"\n",
    "    Use linear_model to run a linear regression using sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    X = df[feature_cols]\n",
    "    y = df[response_col]\n",
    "    if standardized:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        y = StandardScaler().fit_transform(y.values.reshape(-1, 1))\n",
    "    regression = linear_model.LinearRegression() \n",
    "    regression.fit(X,y)\n",
    "    if print_coef:\n",
    "        try:\n",
    "            print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_))\n",
    "        except TypeError:\n",
    "            print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_[0]))\n",
    "        print('Regression Coefficients: ')\n",
    "        for feature, coef in zip(feature_cols, regression.coef_.flatten()):\n",
    "            print(f'{feature} ~ {coef:.2f}')\n",
    "    return regression.predict(X), regression.score(X,y)\n",
    "\n",
    "def parity_plot(true, pred, r_squared=None, title='', alpha=None, color=None, hue=None):\n",
    "    \"\"\"\n",
    "    plot true vs the predicted data\n",
    "    inputs: 2 list-like (arrays) data structures\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "    if hue is not None:\n",
    "        sns.scatterplot(x=true, y=pred, hue=hue)\n",
    "    else: \n",
    "        if color is None: sns.scatterplot(x=true, y=pred)\n",
    "        else: sns.scatterplot(x=true, y=pred, alpha=alpha, color=color)\n",
    "    min_value = min(min(true), min(pred))\n",
    "    max_value = max(max(true), max(pred))\n",
    "    plt.plot([min_value, max_value],[min_value, max_value], '--', label=\"parity\")\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    sns.despine()\n",
    "    plt.text(1.01, 0.98, r\"$R^2 = {0:.2f}$\".format(r_squared),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=ax.transAxes)\n",
    "    plt.title('Parity Plot: {}'.format(title), size=TITLE_FONT)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()    \n",
    "    \n",
    "def run_regression(data, \n",
    "                   feature_cols = ['Start', \n",
    "                                   'End', \n",
    "                                   'G', \n",
    "                                   'U', \n",
    "                                   'bi', \n",
    "                                   'uni', \n",
    "                                   'duplex', \n",
    "                                   'Pos1', \n",
    "                                   'Pos2', \n",
    "                                   'Pos6', \n",
    "                                   'Pos13', \n",
    "                                   'Pos14', \n",
    "                                   'Pos18', \n",
    "                                   'Dif_5-3', \n",
    "                                   'Content+', \n",
    "                                   'Content-', \n",
    "                                   'Cons+', \n",
    "                                   'Cons-', \n",
    "                                   'Cons_Sum', \n",
    "                                   'Hyb19', \n",
    "                                   'target'\n",
    "                                  ], \n",
    "                     response_col='Activity',\n",
    "                     standardized=False,\n",
    "                     parity=True,\n",
    "                     ):\n",
    "    y_pred, r_squared = linear_regression(data, feature_cols, response_col, standardized = standardized)\n",
    "    if parity: parity_plot(data[response_col], y_pred.flatten(), r_squared)\n",
    "\n",
    "run_regression(data=num_dataset)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8: Build your own MLR model\n",
    "\n",
    "Let's remove some of the problematic features from the previous model. Notice how the coefficient of determination changes as you remove features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact()   \n",
    "def regression_wrapper(Start = True,\n",
    "                       End = True,\n",
    "                       G = True,\n",
    "                       U = True,\n",
    "                       bi = True,\n",
    "                       uni = True,\n",
    "                       duplex = True,\n",
    "                       Pos1 = True,\n",
    "                       Pos2 = True,\n",
    "                       Pos6 = True,\n",
    "                       Pos13 = True,\n",
    "                       Pos14 = True,\n",
    "                       Pos18 = True,\n",
    "                       Dif_5_3 = True,\n",
    "                       Content_plus = True,\n",
    "                       Content_minus = True,\n",
    "                       Cons_plus = True,\n",
    "                       Cons_minus = True,\n",
    "                       Cons_Sum = True,\n",
    "                       Hyb19 = True,\n",
    "                       target = True):\n",
    "    response=\"Activity\"\n",
    "    features = []\n",
    "    if Start: features.append('Start')\n",
    "    if End: features.append('End')\n",
    "    if G: features.append('G')\n",
    "    if U: features.append('U')\n",
    "    if bi: features.append('bi')\n",
    "    if uni: features.append('uni')\n",
    "    if duplex: features.append('duplex')\n",
    "    if Pos1: features.append('Pos1')\n",
    "    if Pos2: features.append('Pos2')\n",
    "    if Pos6: features.append('Pos6')\n",
    "    if Pos13: features.append('Pos13')\n",
    "    if Pos14: features.append('Pos14')\n",
    "    if Pos18: features.append('Pos18')\n",
    "    if Dif_5_3: features.append('Dif_5-3')\n",
    "    if Content_plus: features.append('Content+')\n",
    "    if Content_minus: features.append('Content-')\n",
    "    if Cons_plus: features.append('Cons+')\n",
    "    if Cons_minus: features.append('Cons-')\n",
    "    if Cons_Sum: features.append('Cons_Sum')\n",
    "    if Hyb19: features.append('Hyb19')\n",
    "    if target: features.append('target')        \n",
    "\n",
    "    run_regression(data=num_dataset, feature_cols=features, response_col = response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9-10: You are the quantitative biologist now\n",
    "\n",
    "Go through the process of building the model. You can increase the degrees of your polynomial features, and include interaction terms (covariance) in order to build the model. Notice how the fit of the model changes if you include or don't include a particular value. \n",
    "\n",
    "Try to do this without selecting `test` (final option). Use `test` once you're comfortable with the model performance on validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, k=10):\n",
    "    scores = cross_validate(model, X, y, cv=k,\n",
    "                            scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    print(f\"Training RMSE: {np.mean(-1*scores['train_neg_root_mean_squared_error']):.2f}\")\n",
    "    print(f\"Validation RMSE: {np.mean(-1*scores['test_neg_root_mean_squared_error']):.2f}\")\n",
    "    \n",
    "    print(f\"Training R2: {np.mean(scores['train_r2']):.3f}\")\n",
    "    print(f\"Validation R2: {np.mean(scores['test_r2']):.3f}\")\n",
    "    \n",
    "    return model.fit(X,y)\n",
    "    \n",
    "def do_the_thing(X,y , degrees, interactions, test):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    poly = PolynomialFeatures(degrees, include_bias=True)\n",
    "    # print(poly.get_feature_names_out(input_features=X_train.columns))\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "    poly_features = poly.get_feature_names()\n",
    "    X_test = poly.fit_transform(X_test, poly_features)\n",
    "    X_train_df = pd.DataFrame(X_train, columns=poly_features)\n",
    "    X_test_df = pd.DataFrame(X_test, columns=poly_features)\n",
    "    interaction_list = [feat for feat in poly_features if len(feat.split())!=1]\n",
    "    if not interactions:\n",
    "        X_train_df = X_train_df.drop(interaction_list, axis=1)\n",
    "        X_test_df = X_test_df.drop(interaction_list, axis=1)\n",
    "    print(f\"Number of Parameters: {len(X_train_df.columns)}\")\n",
    "    \n",
    "    model = linear_model.LinearRegression(fit_intercept=False) \n",
    "    cross_validation(model, X_train_df, y_train)\n",
    "    if test:\n",
    "        model.fit(X_train_df, y_train)\n",
    "        y_train_pred = model.predict(X_train_df)\n",
    "        print(X_test_df.shape)\n",
    "        y_test_pred = model.predict(X_test_df)\n",
    "        parity_plot(y_train, y_train_pred.flatten(), r_squared =model.score(X_train_df, y_train), title=\"Training Data\", color=\"grey\", alpha=0.5)\n",
    "        parity_plot(y_test, y_test_pred.flatten(), r_squared =model.score(X_test_df, y_test), title=\"Test Data\", color=\"blue\", alpha=1)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "\n",
    "@widgets.interact(degrees=(1,4))\n",
    "def run(degrees=1, \n",
    "        interactions=False,\n",
    "        Start = True,\n",
    "        End = True,\n",
    "        G = True,\n",
    "        U = True,\n",
    "        bi = True,\n",
    "        uni = True,\n",
    "        duplex = True,\n",
    "        Pos1 = True,\n",
    "        Pos2 = True,\n",
    "        Pos6 = True,\n",
    "        Pos13 = True,\n",
    "        Pos14 = True,\n",
    "        Pos18 = True,\n",
    "        Dif_5_3 = True,\n",
    "        Content_plus = True,\n",
    "        Content_minus = True,\n",
    "        Cons_plus = True,\n",
    "        Cons_minus = True,\n",
    "        Cons_Sum = True,\n",
    "        Hyb19 = True,\n",
    "        target = True,\n",
    "        test=False):\n",
    "    \n",
    "    response=\"Activity\"\n",
    "    features = []\n",
    "    if Start: features.append('Start')\n",
    "    if End: features.append('End')\n",
    "    if G: features.append('G')\n",
    "    if U: features.append('U')\n",
    "    if bi: features.append('bi')\n",
    "    if uni: features.append('uni')\n",
    "    if duplex: features.append('duplex')\n",
    "    if Pos1: features.append('Pos1')\n",
    "    if Pos2: features.append('Pos2')\n",
    "    if Pos6: features.append('Pos6')\n",
    "    if Pos13: features.append('Pos13')\n",
    "    if Pos14: features.append('Pos14')\n",
    "    if Pos18: features.append('Pos18')\n",
    "    if Dif_5_3: features.append('Dif_5-3')\n",
    "    if Content_plus: features.append('Content+')\n",
    "    if Content_minus: features.append('Content-')\n",
    "    if Cons_plus: features.append('Cons+')\n",
    "    if Cons_minus: features.append('Cons-')\n",
    "    if Cons_Sum: features.append('Cons_Sum')\n",
    "    if Hyb19: features.append('Hyb19')\n",
    "    if target: features.append('target')  \n",
    "    X=num_dataset[features]\n",
    "    y=num_dataset[response]\n",
    "    \n",
    "\n",
    "    do_the_thing(X,y,degrees,interactions, test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11-12: Model selection and regularization\n",
    "Great, you've built a model and selected which features to include! Next we will look at regularizing the model. The first plot shows you the magnitude of each of your parameters with different values of lambda using ridge regression. Try out a few different values.\n",
    "\n",
    "The second plot gives you the train and validation results from running the model with three different values of lambda. When deciding which model to select, do we care about training or validation performance more?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = 50, 10\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "coef = 10 * np.random.randn(n_features)\n",
    "y = np.dot(X, coef) + np.random.randn(n_samples)\n",
    "\n",
    "# Define the regularization parameter values\n",
    "lambda_val = [0, 1, 10, 100, 1000]\n",
    "\n",
    "# Define the Ridge regression model\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "@widgets.interact_manual(lambda_val=lambda_val)\n",
    "def plot_ridge(lambda_val):\n",
    "    ridge.alpha = lambda_val\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.set_ylim(-25, 25)\n",
    "    ax.set_xlabel('Coefficient Index (Betas)')\n",
    "    ax.set_ylabel('Coefficient Magnitude')\n",
    "    ax.set_title('Effect of Regularization on Coefficient Magnitude')\n",
    "\n",
    "    # Fit the Ridge model to the data and plot the coefficients\n",
    "    ridge.fit(X, y)\n",
    "    ax.plot(ridge.coef_)\n",
    "\n",
    "    coef_sum = np.sum(np.abs(ridge.coef_))\n",
    "    ax.text(0.5, 0.95, f'Sum of Absolute Parameter Values: {coef_sum:.3f}', transform=ax.transAxes, ha='center')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "n_features = 40\n",
    "\n",
    "# Define a function to generate sample data\n",
    "def generate_data(n_samples=n_samples, n_features=n_features, noise_std=13):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    coef = 10 * np.random.randn(n_features)\n",
    "    y = np.dot(X, coef) + noise_std * np.random.randn(n_samples)\n",
    "    return X, y\n",
    "\n",
    "# Generate some sample data\n",
    "X, y = generate_data()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the regularization parameter values\n",
    "model = {\"model 1 (low lambda)\": 0, \"model 2 (mid lambda)\": 1, \"model 3 (high lambda)\": 10}\n",
    "\n",
    "# Define the Ridge regression model\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "@widgets.interact_manual(model=model)\n",
    "def plot_ridge(model):\n",
    "    ridge.alpha = model\n",
    "\n",
    "    # Fit the Ridge model to the training data\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the training and test data\n",
    "    y_train_pred = ridge.predict(X_train)\n",
    "    y_test_pred = ridge.predict(X_test)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Plot the train and test R^2 values\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(['Train', 'Validation'], [train_r2, test_r2])\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_title(f'$R^2$ with {n_features} features and {n_samples} samples')\n",
    "    ax.set_xlabel('Data Split')\n",
    "    ax.set_ylabel('$R^2$')\n",
    "    ax.text(0, train_r2+0.01, f'{train_r2:.2f}')\n",
    "    ax.text(1, test_r2+0.01, f'{test_r2:.2f}')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Other supervised approaches\n",
    "\n",
    "Congratulations, you are now equipped with enough knowledge to evaluate other types of models rather than solely linear regression (Be careful though, the assumptions and hyperparameters from these other models are __much__ more complicated than MLR, but understanding MLR does equip you to understand these other models). I have proposed three different models, with some minor optimization. (You don't need to know the details, but I am happy to explain if you want to know more)\n",
    "- Random Forest: an ensemble of 100 boosted decision trees, averaged to get a final result.\n",
    "- Support Vector Machines: Similarly to polynomial features, we put the features into a different parameter space, and then perform a regression on those new features. In this case we are using a Radial Basis Function. \n",
    "- Neural Network: Using a bunch of manipulations, neural networks learn features from the original features, and fit a new model. It is based on using Rectified Linear Units.\n",
    "\n",
    "It's okay if that sounds intimidating. Anytime I learn a new ML algorithm it is still intimidating. That being said, we can still use these models and evaluate their performance in the same way as we've been doing. \n",
    "__Note: Even if we can evaluate these models, without understanding the underlying math we cannot understand the ramification of these assumptions on interpreting parameters__. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from sklearn import ensemble, neural_network, svm\n",
    "\n",
    "def rf(X,y):\n",
    "    print('-'*30)\n",
    "    print(\"Random Forest (boosted trees)\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = ensemble.GradientBoostingRegressor(learning_rate=.05, alpha=0.2)\n",
    "    cross_validation(model, X_train, y_train)\n",
    "    model.fit(X_train,y_train)\n",
    "    r2_test = model.score(X_test,y_test)\n",
    "    print(f\"\\nTest R2: {r2_test:.2f}\")\n",
    "    model.fit(X,y)\n",
    "    r2 = model.score(X,y)\n",
    "    y_pred = model.predict(X )\n",
    "    parity_plot(y, y_pred, r_squared=r2,   title=\"RF, all data\")\n",
    "    \n",
    "def svr(X,y):\n",
    "    print('-'*30)\n",
    "    print(\"Support Vector Regression\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = svm.SVR(kernel=\"rbf\",gamma=\"scale\", C=1000)\n",
    "    cross_validation(model, X_train, y_train)\n",
    "    model.fit(X_train,y_train)\n",
    "    r2_test = model.score(X_test,y_test)\n",
    "    print(f\"\\nTest R2: {r2_test:.2f}\")\n",
    "    model.fit(X,y)\n",
    "    r2 = model.score(X,y)\n",
    "    y_pred = model.predict(X )\n",
    "    parity_plot(y, y_pred, r_squared=r2,  title=\"SVR, all data\")\n",
    "    \n",
    "def nn(X,y):\n",
    "    print('-'*30)\n",
    "    print(\"Neural Network Regression (Multi-layer perceptron)\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = neural_network.MLPRegressor(hidden_layer_sizes=(30,30),\n",
    "                                        learning_rate='invscaling',\n",
    "                                        activation=\"relu\", \n",
    "                                        max_iter=1000)\n",
    "    cross_validation(model, X_train, y_train)\n",
    "    model.fit(X_train,y_train)\n",
    "    r2_test = model.score(X_test,y_test)\n",
    "    print(f\"\\nTest R2: {r2_test:.2f}\")\n",
    "    model.fit(X,y)\n",
    "    r2 = model.score(X,y)\n",
    "    y_pred = model.predict(X )\n",
    "    parity_plot(y, y_pred, r_squared=r2, title=\"NN, all data\")\n",
    "    \n",
    "features = ['bi', 'uni', 'duplex', \n",
    "            'Pos1', 'Pos2', 'Pos6', 'Pos13', 'Pos14', 'Pos18', \n",
    "            'Dif_5-3', 'Content+', \n",
    "            'Cons+', 'Cons-', 'Cons_Sum', 'Hyb19', 'target']\n",
    "\n",
    "X= num_dataset[features]\n",
    "y= num_dataset[\"Activity\"]\n",
    "\n",
    "rf(X,y)\n",
    "svr(X,y)\n",
    "nn(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
